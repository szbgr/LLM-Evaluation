# LLM-Evaluation
Our group developed an interface to evaluate LLM outputs for Greta's practical work.
It was initially intended as a static site since the questions and answers were in LaTeX and hard to evaluate without rendering.
Seeking improvement, we opted for Streamlit to enable direct user interactions for ratings and comments, with results downloadable as a JSON file. We integrated the earlier visualization project to showcase rating distributions. This new repository was created for the Streamlit app, addressing previous copyright issues (therefore the lack of commits).
